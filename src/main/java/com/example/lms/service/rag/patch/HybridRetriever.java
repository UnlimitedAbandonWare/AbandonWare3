package com.example.lms.service.rag;

import com.example.rag.fusion.WeightedRRF;
import com.example.retrieval.KAllocator;
import com.example.moe.GateVector;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import com.example.lms.service.rag.fusion.ReciprocalRankFuser;
import com.example.lms.service.rag.handler.RetrievalHandler;
import com.example.lms.search.QueryHygieneFilter;
import com.example.lms.util.SoftmaxUtil;
import org.springframework.beans.factory.annotation.Autowired;
import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.rag.content.Content;
import dev.langchain4j.rag.content.retriever.ContentRetriever;
import dev.langchain4j.rag.query.Query;
import com.example.lms.service.rag.QueryUtils;
import dev.langchain4j.store.embedding.EmbeddingStore;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;
import lombok.RequiredArgsConstructor;
import com.example.lms.service.rag.rerank.LightWeightRanker;
import com.example.lms.transform.QueryTransformer;
import com.example.lms.prompt.PromptContext;
import java.lang.reflect.Method;
import java.util.*;
import java.util.stream.Collectors;
import java.util.concurrent.ForkJoinPool;
import com.example.lms.service.rag.auth.AuthorityScorer;
import com.example.lms.util.MLCalibrationUtil;
import com.example.lms.service.scoring.AdaptiveScoringService;
import com.example.lms.service.knowledge.KnowledgeBaseService;
import com.example.lms.learning.NeuralPathFormationService;
import com.example.lms.service.rag.rerank.RerankGate;


import dev.langchain4j.rag.query.Metadata; // [HARDENING] 1.0.x Query ë©”íƒ€ íƒ€ì…
import java.util.Map; // [HARDENING]
// imports
import com.example.lms.service.rag.rerank.ElementConstraintScorer;  //  ì‹ ê·œ ì¬ë­ì»¤



import com.example.lms.service.config.HyperparameterService;   // â˜… NEW
import org.springframework.beans.factory.annotation.Qualifier; // - FIX: ë‹¤ì¤‘ ë¹ˆ ëª¨í˜¸ì„± í•´ê²°ìš© @Qualifier
import jakarta.annotation.PostConstruct; // + ê°œì„ : í”„ë¡œí¼í‹° ê¸°ë°˜ ë°±ì—”ë“œ ì„ íƒ ì§€ì›
@Component
@RequiredArgsConstructor
public class HybridRetriever implements ContentRetriever {
    private static final Logger log = LoggerFactory.getLogger(HybridRetriever.class);

    // fields (ë‹¤ë¥¸ final í•„ë“œë“¤ê³¼ ê°™ì€ ìœ„ì¹˜)
    private final LightWeightRanker lightWeightRanker;
    // Gate controlling invocation of the expensive cross-encoder reranker.
    private final com.example.lms.service.rag.rerank.RerankGate rerankGate;
    private final AuthorityScorer authorityScorer;
    private static final double GAME_SIM_THRESHOLD = 0.3;

    // ë©”íƒ€í‚¤ (í•„ìš” ì‹œ Query.metadataì— ì‹¤ì–´ ì „ë‹¬)
    private static final String META_ALLOWED_DOMAINS = "allowedDomains";   // List<String>
    private static final String META_MAX_PARALLEL = "maxParallel";      // Integer
    private static final String META_DEDUPE_KEY = "dedupeKey";        // "text" | "url" | "hash"
    private static final String META_OFFICIAL_DOMAINS = "officialDomains";  // List<String>

    @Value("${rag.search.top-k:5}")
    private int topK;

    // ì²´ì¸ & ìœµí•©ê¸°
    private final RetrievalHandler handlerChain;
    private final ReciprocalRankFuser fuser;
    // Optional weighted RRF fuser.  When present and the fusionMode is set
    // appropriately (e.g. "weighted-rrf"), the hybrid retriever will use it
    // instead of the standard RRF fuser.  The WeightedReciprocalRankFuser
    // supports per-source weights tuned at runtime via the HyperparameterService.
    @Autowired(required = false)
    private com.example.lms.service.rag.fusion.WeightedReciprocalRankFuser weightedFuser;
    private final AnswerQualityEvaluator qualityEvaluator;
    private final SelfAskPlanner selfAskPlanner;
    private final RelevanceScoringService relevanceScoringService;
    private final HyperparameterService hp; // â˜… NEW: ë™ì  ê°€ì¤‘ì¹˜ ë¡œë”
    private final ElementConstraintScorer elementConstraintScorer; // â˜… NEW: ì›ì†Œ ì œì•½ ì¬ë­ì»¤
    private final QueryTransformer queryTransformer;               // â˜… NEW: ìƒíƒœ ê¸°ë°˜ ì§ˆì˜ ìƒì„±
    private final AdaptiveScoringService scoring;
    private final KnowledgeBaseService kb;
    // Path formation service used to reinforce high-consistency entity pairs.
    private final NeuralPathFormationService pathFormation;

    /**
     * Optional Redis-backed cooldown service used to guard expensive
     * operations such as cross-encoder reranking.  When configured this
     * service attempts to acquire a short-lived lock prior to invoking
     * the reranker.  If the lock is unavailable the reranking step is
     * skipped, allowing the system to fall back to the first pass
     * ranking.  The field may be null when no Redis instance is
     * available or when cooldown gating is disabled.
     */
    @Autowired(required = false)
    private com.example.lms.service.redis.RedisCooldownService cooldownService;

    // ğŸ”´ NEW: êµì°¨ì—”ì½”ë” ê¸°ë°˜ ì¬ì •ë ¬(ì—†ìœ¼ë©´ ìŠ¤í‚µ)
    @Autowired(required = false)
    @Qualifier("noopCrossEncoderReranker") // - FIX: ë¹ˆ 3ê°œ(onnx/noop/embedding) ì¶©ëŒ â†’ ê¸°ë³¸ noopë¡œ ëª…ì‹œ
    private com.example.lms.service.rag.rerank.CrossEncoderReranker crossEncoderReranker;

    @Autowired(required = false)
    private Map<String, com.example.lms.service.rag.rerank.CrossEncoderReranker> rerankers = java.util.Collections.emptyMap(); // + ê°œì„ : ëŸ°íƒ€ì„ì— ë°±ì—”ë“œ ìŠ¤ìœ„ì¹­ ê°€ëŠ¥

    @Value("${abandonware.reranker.backend:noop}")
    private String rerankerBackend; // + ê°œì„ : í”„ë¡œí¼í‹°ë¡œ onnx/embedding/noop ì„ íƒ

    // ë¦¬íŠ¸ë¦¬ë²„ë“¤
    private final SelfAskWebSearchRetriever selfAskRetriever;
    private final AnalyzeWebSearchRetriever analyzeRetriever;
    private final WebSearchRetriever webSearchRetriever;
    private final QueryComplexityGate gate;

    // (ì˜µì…˜) íƒ€ì‚¬ ê²€ìƒ‰ê¸° - ìˆìœ¼ë©´ ë¶€ì¡±ë¶„ ë³´ê°•ì— ì‚¬ìš©
    @Autowired(required = false)
    @org.springframework.beans.factory.annotation.Qualifier("tavilyWebSearchRetriever")
    private ContentRetriever tavilyWebSearchRetriever;
    // RAG/ì„ë² ë”©
    private final LangChainRAGService ragService;
    private final EmbeddingModel embeddingModel;
    private final EmbeddingStore<TextSegment> gameEmbeddingStore;

    // ---------------------------------------------------------------------
    // Domain detector for selecting the appropriate Pinecone index.  When the
    // domain is GENERAL a dedicated general index may be used (configured via
    // pinecone.index.general).  When null the default index (pinecone.index.name)
    // will be used for all domains.
    private final com.example.lms.service.rag.detector.GameDomainDetector domainDetector;

    /**
     * Name of the Pinecone index used for GENERAL domain queries.  When this
     * property is blank or undefined the default pineconeIndexName will be
     * used instead.  Configure via application.yml: pinecone.index.general.
     */
    @org.springframework.beans.factory.annotation.Value("${pinecone.index.general:}")
    private String pineconeIndexGeneral;

    /**
     * Choose the appropriate index name based on the detected domain.  If
     * the domain is GENERAL and a general index has been configured via
     * pinecone.index.general then that index is returned; otherwise the
     * default pineconeIndexName is used.
     *
     * @param domain the detected domain (case-insensitive)
     * @
        return the name of the pinecone index to query
     */
    private String chooseIndex(String domain) {
        if (domain != null && "GENERAL".equalsIgnoreCase(domain)) {
            if (pineconeIndexGeneral != null && !pineconeIndexGeneral.isBlank()) {
                return pineconeIndexGeneral;
            }
        }
        return pineconeIndexName;
    }

    @Value("${pinecone.index.name}")
    private String pineconeIndexName;

    @Value("${hybrid.debug.sequential:false}")
    private boolean debugSequential;
    @Value("${hybrid.progressive.quality-min-docs:4}")
    private int qualityMinDocs;
    @Value("${hybrid.progressive.quality-min-score:0.62}")
    private double qualityMinScore;
    @Value("${hybrid.max-parallel:3}")
    private int maxParallel;

    @Value("${hybrid.min-relatedness:0.4}")  //  ê´€ë ¨ë„ í•„í„° ì»·ì˜¤í”„
    private double minRelatedness;
    // â˜… ìœµí•© ëª¨ë“œ: rrf(ê¸°ë³¸) | softmax
    @Value("${retrieval.fusion.mode:rrf}")
    private String fusionMode;
    // â˜… softmax ìœµí•© ì˜¨ë„
    @Value("${retrieval.fusion.softmax.temperature:1.0}")
    private double fusionTemperature;

    /**
     * Calibration mode for softmax fusion.  Supported values are
     * {@code minmax}, {@code isotonic} and {@code none}.  When set to
     * {@code none} or any unsupported value the softmax fusion pathway is
     * disabled and the system will fall back to RRF.  This value is
     * configurable via application.yml (retrieval.fusion.softmax.calibration).
     */
    @Value("${retrieval.fusion.softmax.calibration:none}")
    private String softmaxCalibration;

    /**
     * The number of candidates that will be sent to the cross-encoder reranker.
     * This value is used by the rerank gate to decide whether or not to invoke
     * the expensive cross-encoder reordering step.  When the first pass
     * candidate set contains fewer than this number of elements the reranker
     * is skipped.  Defaults to 12 if unspecified (ranking.rerank.ce.topK).
     */
    @Value("${ranking.rerank.ce.topK:12}")
    private int rerankCeTopK;
    @Value("${retrieval.rank.use-ml-correction:true}")
    private boolean useMlCorrection;  // â˜… NEW: ML ë³´ì • ì˜¨/ì˜¤í”„

    /** ê²€ìƒ‰ ì¼ê´€ì„± â†’ ì•”ë¬µ ê°•í™” ì„ê³„ì¹˜ */
    @Value("${retrieval.consistency.threshold:0.8}")
    private double consistencyThreshold;

    @PostConstruct
    private void selectRerankerByProperty() {
        // + ê°œì„ : application.yml ì˜ abandonware.reranker.backend ê°’ì— ë”°ë¼ ë°±ì—”ë“œ ìë™ ì„ íƒ
        try {
            String key = rerankerBackend + "CrossEncoderReranker";
            var chosen = rerankers.get(key);
            if (chosen != null) {
                this.crossEncoderReranker = chosen;
                log.info("[Hybrid] CrossEncoderReranker set via property: {}", key); // + ê°œì„ : ê°€ì‹œì„± ë¡œê·¸
            } else {
                log.info("[Hybrid] backend='{}' not found; using default: {}", rerankerBackend,
                        (crossEncoderReranker != null ? crossEncoderReranker.getClass().getSimpleName() : "none"));
            }
        } catch (Exception ignore) {
            // ì•ˆì „: ì„ íƒ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì£¼ì… ìœ ì§€
        }
    }

    @Override
    public List<Content> retrieve(Query query) {

        // 0) ë©”íƒ€ íŒŒì‹±
        String sessionKey = Optional.ofNullable(query)
                .map(Query::metadata)
                .map(HybridRetriever::toMap)
                .map(md -> md.get(LangChainRAGService.META_SID))
                .map(Object::toString)
                .orElse(null);

        Map<String, Object> md = Optional.ofNullable(query)
                .map(Query::metadata)
                .map(HybridRetriever::toMap)
                .orElse(Map.of());

        @SuppressWarnings("unchecked")
        List<String> allowedDomains =
                (List<String>) md.getOrDefault(META_ALLOWED_DOMAINS, List.of());
        @SuppressWarnings("unchecked")
        List<String> officialDomains =
                (List<String>) md.getOrDefault(META_OFFICIAL_DOMAINS, allowedDomains);

        // ë©”íƒ€ì— ë“¤ì–´ì˜¨ ë³‘ë ¬ ìƒí•œ(ì—†ìœ¼ë©´ ê¸°ë³¸ì„¤ì • ì‚¬ìš©)
        int maxParallelOverride = Optional.ofNullable((Integer) md.get(META_MAX_PARALLEL)).orElse(this.maxParallel);
        String dedupeKey = (String) md.getOrDefault(META_DEDUPE_KEY, "text");

        LinkedHashSet<Content> mergedContents = new LinkedHashSet<>();

        // 1) ë‚œì´ë„ ê²Œì´íŒ…
        final String q = (query != null && query.text() != null) ? query.text().strip() : "";

        // Determine the query domain once up front.  When the domain detector is
        // unavailable default to GENERAL.  The domain is used when selecting
        // which Pinecone index to query via chooseIndex().
        String detectedDomain;
        try {
            detectedDomain = (domainDetector != null) ? domainDetector.detect(q) : "GENERAL";
        } catch (Exception ignore) {
            detectedDomain = "GENERAL";
        }
        final String chosenIndex = chooseIndex(detectedDomain);

        // â”€â”€ ì¡°ê±´ë¶€ íŒŒì´í”„ë¼ì¸: êµìœ¡/êµ­ë¹„ í‚¤ì›Œë“œ â†’ ë²¡í„° ê²€ìƒ‰ ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try {
            String qLower = q.toLowerCase(java.util.Locale.ROOT);
            if (qLower.contains("í•™ì›") || qLower.contains("êµ­ë¹„")) {
                ContentRetriever pineRetriever = ragService.asContentRetriever(chosenIndex);
                List<Content> vectResults = pineRetriever.retrieve(query);
                // deduplicate results while preserving order
                LinkedHashSet<Content> unique = new LinkedHashSet<>(vectResults);
                List<Content> deduped = new ArrayList<>(unique);
                // rank by cosine similarity.
                try {
                    deduped.sort((c1, c2) -> {
                        String t1 = java.util.Optional.ofNullable(c1.textSegment())
                                .map(dev.langchain4j.data.segment.TextSegment::text)
                                .orElse(c1.toString());
                        String t2 = java.util.Optional.ofNullable(c2.textSegment())
                                .map(dev.langchain4j.data.segment.TextSegment::text)
                                .orElse(c2.toString());
                        double s1 = cosineSimilarity(q, t1);
                        double s2 = cosineSimilarity(q, t2);
                        return Double.compare(s2, s1);
                    });
                } catch (Exception ignore) {
                    // if ranking fails, maintain original order
                }
                // limit to topK
                List<Content> topList = deduped.size() > topK ? deduped.subList(0, topK) : deduped;
                // finalise and return
                return finalizeResults(new ArrayList<>(topList), dedupeKey, officialDomains, q);
            }
        } catch (Exception ignore) {
            // on error continue with default behaviour
        }

        QueryComplexityGate.Level level = gate.assess(q);
        log.debug("[Hybrid] level={} q='{}'", level, q);

        switch (level) {
            case SIMPLE -> {
                // ì›¹ ìš°ì„ , ë¶€ì¡±í•˜ë©´ ë²¡í„°
                mergedContents.addAll(webSearchRetriever.retrieve(query));
                if (mergedContents.size() < topK) {
                    ContentRetriever pine = ragService.asContentRetriever(chosenIndex);
                    mergedContents.addAll(pine.retrieve(query));
                }
                if (mergedContents.size() < topK && tavilyWebSearchRetriever != null) {
                    try { mergedContents.addAll(tavilyWebSearchRetriever.retrieve(query)); }
                    catch (Exception e) { log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString()); }
                }
            }
            case AMBIGUOUS -> {
                mergedContents.addAll(analyzeRetriever.retrieve(query));
                if (mergedContents.size() < topK) mergedContents.addAll(webSearchRetriever.retrieve(query));
                if (mergedContents.size() < topK) {
                    ContentRetriever pine = ragService.asContentRetriever(chosenIndex);
                    mergedContents.addAll(pine.retrieve(query));
                }
                if (mergedContents.size() < topK && tavilyWebSearchRetriever != null) {
                    try { mergedContents.addAll(tavilyWebSearchRetriever.retrieve(query)); }
                    catch (Exception e) { log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString()); }
                }
            }
            case COMPLEX -> {
                mergedContents.addAll(selfAskRetriever.retrieve(query));
                if (mergedContents.size() < topK) mergedContents.addAll(analyzeRetriever.retrieve(query));
                if (mergedContents.size() < topK) mergedContents.addAll(webSearchRetriever.retrieve(query));
                if (mergedContents.size() < topK) {
                    ContentRetriever pine = ragService.asContentRetriever(chosenIndex);
                    mergedContents.addAll(pine.retrieve(query));
                }
                if (mergedContents.size() < topK && tavilyWebSearchRetriever != null) {
                    try { mergedContents.addAll(tavilyWebSearchRetriever.retrieve(query)); }
                    catch (Exception e) { log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString()); }
                }

            }
        }

        // ìµœì¢… ì •ì œ
        List<Content> out = finalizeResults(new ArrayList<>(mergedContents), dedupeKey, officialDomains, q);

        // â”€ ì•”ë¬µ í”¼ë“œë°±(ê²€ìƒ‰ ì¼ê´€ì„±) ë°˜ì˜
        try { maybeRecordImplicitConsistency(q, out, officialDomains); } catch (Exception ignore) {}

        return out;
    }


    private static boolean containsAny(String text, String[] cues) {
        if (text == null) return false;
        String t = text.toLowerCase(java.util.Locale.ROOT);
        for (String c : cues) if (t.contains(c)) return true;
        return false;
    }

    private static final String[] SYNERGY_CUES = {"ì‹œë„ˆì§€", "ì¡°í•©", "ê¶í•©", "í•¨ê»˜", "ì–´ìš¸", "ì½¤ë³´"};

    private void maybeRecordImplicitConsistency(String queryText, List<Content> contents, List<String> officialDomains) {
        if (scoring == null || kb == null || contents == null || contents.isEmpty()) return;
        String domain = kb.inferDomain(queryText);
        var ents = kb.findMentionedEntities(domain, queryText);
        if (ents == null || ents.size() < 2) return;
        var it = ents.iterator();
        String subject = it.next();
        String partner = it.next();
        int total = 0, hit = 0;
        for (Content c : contents) {
            String text = java.util.Optional.ofNullable(c.textSegment())
                    .map(dev.langchain4j.data.segment.TextSegment::text)
                    .orElse(c.toString());
            String url  = extractUrl(text);
            boolean both = text != null
                    && text.toLowerCase(java.util.Locale.ROOT).contains(subject.toLowerCase(java.util.Locale.ROOT))
                    && text.toLowerCase(java.util.Locale.ROOT).contains(partner.toLowerCase(java.util.Locale.ROOT));
            if (both) {
                total++;
                double w = containsAny(text, SYNERGY_CUES) ? 1.0 : 0.6; // ì‹œë„ˆì§€ ë‹¨ì„œ ë³´ë„ˆìŠ¤
                if (isOfficial(url, officialDomains)) w += 0.1; // ê³µì‹ ë„ë©”ì¸ ë³´ë„ˆìŠ¤
                if (w >= 0.9) hit++; // ê°•í•œ ì§€ì§€ë¡œ ì¹´ìš´íŠ¸
            }
        }
        if (total <= 0) return;
        double consistency = hit / (double) total;
        scoring.applyImplicitPositive(domain, subject, partner, consistency);
        // If the consistency score is high enough, attempt to persist the path for future alignment.
        try {
            if (pathFormation != null) {
                pathFormation.maybeFormPath(subject + "->" + partner, consistency);
            }
        } catch (Throwable ignore) {
            // path reinforcement failures should not break retrieval
        }
    }

    /**
     * Progressive retrieval:
     * 1) Local RAG ìš°ì„  â†’ í’ˆì§ˆ ì¶©ë¶„ ì‹œ ì¡°ê¸° ì¢…ë£Œ
     * 2) ë¯¸í¡ ì‹œ Self-Ask(1~2ê°œ)ë¡œ ì •ì œëœ ì›¹ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
     */
    @Deprecated // â† í­í¬ìˆ˜ ê²€ìƒ‰ ë¹„í™œì„±í™” ê²½ë¡œ(ë‚¨ê²¨ë‘ë˜ í˜¸ì¶œì€ ë‚¨ê¹€)
    public List<Content> retrieveProgressive(String question, String sessionKey, int limit) {
        if (question == null || question.isBlank()) {
            return List.of(Content.from("[ë¹ˆ ì§ˆì˜]"));
        }
        final int top = Math.max(1, limit);

        try {
            // 1) ë¡œì»¬ RAG ìš°ì„ 
            // Detect the domain of the question and select the appropriate pinecone index.
            String domain;
            try {
                domain = (domainDetector != null) ? domainDetector.detect(question) : "GENERAL";
            } catch (Exception ignore) {
                domain = "GENERAL";
            }
            String idx = chooseIndex(domain);
            ContentRetriever pine = ragService.asContentRetriever(idx);
            // [HARDENING] build query with metadata for session isolation
            String sidForQuery = (sessionKey == null || sessionKey.isBlank()) ? "__TRANSIENT__" : sessionKey;
            dev.langchain4j.rag.query.Query qObj =
                    QueryUtils.buildQuery(question, sidForQuery, null);
            List<Content> local = pine.retrieve(qObj);

            if (qualityEvaluator != null && qualityEvaluator.isSufficient(question, local, qualityMinDocs, qualityMinScore)) {
                log.info("[Hybrid] Local RAG sufficient â†’ skip web (sid={}, q='{}')", sessionKey, question);
                List<Content> out = finalizeResults(new ArrayList<>(local), "text", java.util.Collections.emptyList(), question);
                return out.size() > top ? out.subList(0, top) : out;
            }

            // 2) Self-Askë¡œ 1~2ê°œ í•µì‹¬ ì§ˆì˜ ìƒì„± â†’ ìœ„ìƒ í•„í„°
            List<String> planned = (selfAskPlanner != null) ? selfAskPlanner.plan(question, 2) : List.of(question);
            List<String> queries = QueryHygieneFilter.sanitize(planned, 2, 0.80);

            if (queries.isEmpty()) queries = List.of(question);

            // 3) í•„ìš”í•œ ì¿¼ë¦¬ë§Œ ìˆœì°¨ ì²˜ë¦¬ â†’ ìœµí•©
            List<List<Content>> buckets = new ArrayList<>();
            for (String q : queries) {
                List<Content> acc = new ArrayList<>();
                try {
                    // [HARDENING] build a query with session metadata using QueryUtils
                    dev.langchain4j.rag.query.Query subQ =
                            QueryUtils.buildQuery(q, sidForQuery, null);
                    handlerChain.handle(subQ, acc);
                } catch (Exception e) {
                    log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", e.toString());
                }
                buckets.add(acc);
            }

            // ìœµí•© ë° ìµœì¢… ì •ì œ í›„ ìƒìœ„ top ë°˜í™˜
            // Select the fusion strategy.  Softmax fusion is enabled only when
            // the mode is set to 'softmax' and a valid calibration is provided.
            List<Content> fused;
            boolean useSoftmax = "softmax".equalsIgnoreCase(fusionMode)
                    && ("minmax".equalsIgnoreCase(softmaxCalibration)
                        || "isotonic".equalsIgnoreCase(softmaxCalibration));
            if (useSoftmax) {
                fused = fuseWithSoftmax(buckets, top, question);
            } else {
                // Weighted RRF support: if the fusion mode is marked as weighted
                // and a weighted fuser is available, prefer it over the
                // unweighted RRF.  Recognised values include "weighted-rrf",
                // "rrf-weighted" and "weighted".
                boolean useWeighted = weightedFuser != null &&
                        ("weighted-rrf".equalsIgnoreCase(fusionMode) ||
                         "rrf-weighted".equalsIgnoreCase(fusionMode) ||
                         "weighted".equalsIgnoreCase(fusionMode));
                if (useWeighted) {
                    fused = weightedFuser.fuse(buckets, top);
                } else {
                    fused = fuser.fuse(buckets, top);
                }
            }
            List<Content> combined = new ArrayList<>(local); // 'local'ì€ ì´ ë©”ì†Œë“œ ìƒë‹¨ì—ì„œ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
            combined.addAll(fused);

            List<Content> out = finalizeResults(combined, "text", java.util.Collections.emptyList(), question);
            return out.size() > top ? out.subList(0, top) : out;

        } catch (Exception e) {
            log.error("[Hybrid] retrieveProgressive ì‹¤íŒ¨(sid={}, q='{}')", sessionKey, question, e);
            return List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
    }

    /**
     * Progressive retrieval with optional routing hints.  This overload accepts a map of
     * metadata hints (precision search, depth, webTopK, etc.) which will be embedded into
     * the Query metadata.  When hints are provided the downstream web search handler can
     * adjust its behaviour accordingly (e.g. precision scanning).  When no hints are
     * provided the default behaviour is equivalent to the legacy retrieveProgressive
     * method.
     *
     * @param question    the user question
     * @param sessionKey  unique session identifier for isolation
     * @param limit       number of items to return
     * @param metaHints   optional metadata hints to embed into the query
     * @return list of retrieved content
     */
    public java.util.List<Content> retrieveProgressive(String question, String sessionKey, int limit,
                                                       java.util.Map<String, Object> metaHints) {
        if (question == null || question.isBlank()) {
            return java.util.List.of(Content.from("[ë¹ˆ ì§ˆì˜]"));
        }
        final int top = Math.max(1, limit);

        try {
            // 1) Local RAG first
            String domain;
            try {
                domain = (domainDetector != null) ? domainDetector.detect(question) : "GENERAL";
            } catch (Exception ignore) {
                domain = "GENERAL";
            }
            String idx = chooseIndex(domain);
            ContentRetriever pine = ragService.asContentRetriever(idx);
            String sidForQuery = (sessionKey == null || sessionKey.isBlank()) ? "__TRANSIENT__" : sessionKey;
            // Merge default metadata with hints and SID
            java.util.Map<String, Object> mdMap = new java.util.HashMap<>();
            mdMap.put(com.example.lms.service.rag.LangChainRAGService.META_SID, sidForQuery);
            if (metaHints != null) mdMap.putAll(metaHints);
            mdMap.putIfAbsent("depth", "LIGHT");
            mdMap.putIfAbsent("webTopK", top);
            dev.langchain4j.data.document.Metadata md = dev.langchain4j.data.document.Metadata.from(mdMap);
            dev.langchain4j.rag.query.Query qObj;
            try {
                qObj = new dev.langchain4j.rag.query.Query(question, md);
            } catch (Throwable t) {
                qObj = dev.langchain4j.rag.query.Query.builder().text(question).metadata(md).build();
            }
            java.util.List<Content> local = pine.retrieve(qObj);
            if (qualityEvaluator != null && qualityEvaluator.isSufficient(question, local, qualityMinDocs, qualityMinScore)) {
                java.util.List<Content> out = finalizeResults(new java.util.ArrayList<>(local), "text", java.util.Collections.emptyList(), question);
                return out.size() > top ? out.subList(0, top) : out;
            }
            // Self-Ask / hygiene filter
            java.util.List<String> planned = (selfAskPlanner != null) ? selfAskPlanner.plan(question, 2) : java.util.List.of(question);
            java.util.List<String> queries = com.example.lms.search.QueryHygieneFilter.sanitize(planned, 2, 0.80);
            if (queries.isEmpty()) queries = java.util.List.of(question);
            java.util.List<java.util.List<Content>> buckets = new java.util.ArrayList<>();
            for (String q : queries) {
                java.util.List<Content> acc = new java.util.ArrayList<>();
                try {
                    java.util.Map<String, Object> subMd = new java.util.HashMap<>(mdMap);
                    // LangChain4j v1.0.1 does not support Boolean metadata values.
                    // Encode booleans as strings to avoid IllegalArgumentException at runtime.
                    subMd.put("subQuery", "true");
                    dev.langchain4j.data.document.Metadata subMdObj = dev.langchain4j.data.document.Metadata.from(subMd);
                    dev.langchain4j.rag.query.Query subQ;
                    try {
                        subQ = new dev.langchain4j.rag.query.Query(q, subMdObj);
                    } catch (Throwable t) {
                        subQ = dev.langchain4j.rag.query.Query.builder().text(q).metadata(subMdObj).build();
                    }
                    handlerChain.handle(subQ, acc);
                } catch (Exception e) {
                    log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", e.toString());
                }
                buckets.add(acc);
            }
            // Fusion and finalization
            java.util.List<Content> fused;
            boolean useSoftmax = "softmax".equalsIgnoreCase(fusionMode)
                    && ("minmax".equalsIgnoreCase(softmaxCalibration)
                        || "isotonic".equalsIgnoreCase(softmaxCalibration));
            if (useSoftmax) {
                fused = fuseWithSoftmax(buckets, top, question);
            } else {
                boolean useWeighted = weightedFuser != null &&
                        ("weighted-rrf".equalsIgnoreCase(fusionMode) ||
                         "rrf-weighted".equalsIgnoreCase(fusionMode) ||
                         "weighted".equalsIgnoreCase(fusionMode));
                if (useWeighted) {
                    fused = weightedFuser.fuse(buckets, top);
                } else {
                    fused = fuser.fuse(buckets, top);
                }
            }
            java.util.List<Content> combined = new java.util.ArrayList<>(local);
            combined.addAll(fused);
            java.util.List<Content> out = finalizeResults(combined, "text", java.util.Collections.emptyList(), question);
            return out.size() > top ? out.subList(0, top) : out;
        } catch (Exception e) {
            log.error("[Hybrid] retrieveProgressive ì‹¤íŒ¨(sid={}, q='{}')", sessionKey, question, e);
            return java.util.List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
    }

    /**
     * ë‹¤ì¤‘ ì¿¼ë¦¬ ë³‘ë ¬ ê²€ìƒ‰ + RRF ìœµí•©
     */
    public List<Content> retrieveAll(List<String> queries, int limit) {
        if (queries == null || queries.isEmpty()) {
            return List.of(Content.from("[ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ]"));
        }

        try {
            List<List<Content>> results;
            if (debugSequential) {
                log.warn("[Hybrid] debug.sequential=true â†’ handlerChain ìˆœì°¨ ì‹¤í–‰");
                results = new ArrayList<>();
                for (String q : queries) {
                    List<Content> acc = new ArrayList<>();
                    try {
                        // [HARDENING] build query with __TRANSIENT__ metadata for session isolation
                        dev.langchain4j.rag.query.Query subQ =
                                QueryUtils.buildQuery(q, "__TRANSIENT__", null);
                        handlerChain.handle(subQ, acc);
                    } catch (Exception e) {
                        log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", q, e);
                    }
                    results.add(acc);
                }
            } else {
                // ê¸°ë³¸: ì œí•œ ë³‘ë ¬ ì‹¤í–‰ (ê³µìš© í’€ ì‚¬ìš© ê¸ˆì§€)
                ForkJoinPool pool = new ForkJoinPool(Math.max(1, this.maxParallel));
                try {
                    results = pool.submit(() ->
                            queries.parallelStream()
                                    .map(q -> {
                                        List<Content> acc = new ArrayList<>();
                                        try {
                                            // [HARDENING] build query with session metadata
                                            dev.langchain4j.rag.query.Query subQ =
                                                    QueryUtils.buildQuery(q, "__TRANSIENT__", null);
                                            handlerChain.handle(subQ, acc);
                                        } catch (Exception e) {
                                            log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", q, e);
                                        }
                                        return acc;
                                    })
                                    .toList()
                    ).join();
                } finally {
                    pool.shutdown();
                }
            }
            // RRF or Softmax ìœµí•© í›„ ìƒìœ„ limit ë°˜í™˜.  Softmax is enabled only
            // when fusionMode is 'softmax' and a valid calibration is provided.
            boolean useSoftmax = "softmax".equalsIgnoreCase(fusionMode)
                    && ("minmax".equalsIgnoreCase(softmaxCalibration)
                        || "isotonic".equalsIgnoreCase(softmaxCalibration));
            if (useSoftmax) {
                String q0 = queries.get(0); // representative query (approximation)
                return fuseWithSoftmax(results, Math.max(1, limit), q0);
            }
            // Weighted RRF support for multi-query fusion.  When the fusionMode
            // indicates a weighted variant and a weighted fuser is available,
            // invoke it; otherwise fallback to the standard RRF implementation.
            boolean useWeighted = weightedFuser != null &&
                    ("weighted-rrf".equalsIgnoreCase(fusionMode) ||
                     "rrf-weighted".equalsIgnoreCase(fusionMode) ||
                     "weighted".equalsIgnoreCase(fusionMode));
            if (useWeighted) {
                return weightedFuser.fuse(results, Math.max(1, limit));
            }
            return fuser.fuse(results, Math.max(1, limit));
        } catch (Exception e) { // retrieveAll ì¢…ë£Œ
            log.error("[Hybrid] retrieveAll ì‹¤íŒ¨", e);
            return List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
        // í´ë˜ìŠ¤ ì¢…ë£ŒëŠ” íŒŒì¼ ë§ë¯¸ë¡œ ì´ë™ (í—¬í¼ ë©”ì„œë“œ í¬í•¨)

    } // retrieveAll ë


    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // ìƒíƒœ ê¸°ë°˜ ê²€ìƒ‰: CognitiveState/PromptContextë¥¼ ë°˜ì˜í•´ ì¿¼ë¦¬ í™•ì¥ â†’ ë³‘ë ¬ ê²€ìƒ‰
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    public List<Content> retrieveStateDriven(PromptContext ctx, int limit) {
        String userQ = Optional.ofNullable(ctx.userQuery()).orElse("");
        String lastA = ctx.lastAssistantAnswer();
        String subject = ctx.subject();
        // QueryTransformerì˜ í™•ì¥ API í™œìš©
        List<String> queries = queryTransformer.transformEnhanced(userQ, lastA, subject);
        if (queries.isEmpty()) queries = List.of(userQ);
        return retrieveAll(queries, Math.max(1, limit));
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * (ì˜µì…˜) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ - í•„ìš” ì‹œ ì‚¬ìš©
     */
    private double cosineSimilarity(String q, String doc) {
        try {
            var qVec = embeddingModel.embed(q).content().vector();
            var dVec = embeddingModel.embed(doc).content().vector();
            if (qVec.length != dVec.length) {
                throw new IllegalArgumentException("Embedding dimension mismatch");
            }
            double dot = 0, nq = 0, nd = 0;
            for (int i = 0; i < qVec.length; i++) {
                dot += qVec[i] * dVec[i];
                nq += qVec[i] * qVec[i];
                nd += dVec[i] * dVec[i];
            }
            if (nq == 0 || nd == 0) return 0d;
            return dot / (Math.sqrt(nq) * Math.sqrt(nd) + 1e-9);
        } catch (Exception e) {
            return 0d;
        }
    }

    @SuppressWarnings("unchecked")
    private static Map<String, Object> toMap(Object meta) {
        if (meta == null) return Map.of();
        // LangChain4j 1.0.x: rag.query.Metadata â†’ chatMemoryIdë¡œ sid ì „ë‹¬ë¨
        if (meta instanceof dev.langchain4j.rag.query.Metadata m) {
            Object sid = m.chatMemoryId();
            return (sid != null)
                    ? java.util.Map.of(com.example.lms.service.rag.LangChainRAGService.META_SID, sid)
                    : java.util.Map.of();
        }
        try {
            Method m = meta.getClass().getMethod("asMap");
            return (Map<String, Object>) m.invoke(meta);
        } catch (NoSuchMethodException e) {
            try {
                Method m = meta.getClass().getMethod("map");
                return (Map<String, Object>) m.invoke(meta);
            } catch (Exception ex) {
                return Map.of();
            }
        } catch (Exception ex) {
            return Map.of();
        }
    }

    private static String extractUrl(String text) {
        if (text == null) return null;
        int a = text.indexOf("href=\"");
        if (a >= 0) {
            int s = a + 6, e = text.indexOf('"', s);
            if (e > s) return text.substring(s, e);
        }
        int http = text.indexOf("http");
        if (http >= 0) {
            int sp = text.indexOf(' ', http);
            return sp > http ? text.substring(http, sp) : text.substring(http);
        }
        return null;
    }

    private static boolean isOfficial(String url, List<String> officialDomains) {
        if (url == null || officialDomains == null) return false;
        for (String d : officialDomains) {
            if (d != null && !d.isBlank() && url.contains(d.trim())) return true;
        }
        return false;
    }

    /**
     * ìµœì¢… ì •ì œ:
     * - dedupeKey ê¸°ì¤€ ì¤‘ë³µ ì œê±°
     * - ê³µì‹ ë„ë©”ì¸ ë³´ë„ˆìŠ¤(+0.20)
     * - ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ topK ë°˜í™˜
     */
    private List<Content> finalizeResults(List<Content> raw,
                                          String dedupeKey,
                                          List<String> officialDomains,
                                          String queryText) {

        // 1) ì¤‘ë³µ ì œê±° + ì €ê´€ë ¨ í•„í„°
        Map<String, Content> uniq = new LinkedHashMap<>();
        for (Content c : raw) {
            if (c == null) continue;

            String text = Optional.ofNullable(c.textSegment())
                    .map(TextSegment::text)
                    .orElse(c.toString());

            double rel = 0.0;
            try {
                rel = relevanceScoringService.relatedness(
                        Optional.ofNullable(queryText).orElse(""),
                        text
                );
            } catch (Exception ignore) { }
            if (rel < minRelatedness) continue;

            String key;
            switch (dedupeKey) {
                case "url" -> key = Optional.ofNullable(extractUrl(text)).orElse(text);
                case "hash" -> key = Integer.toHexString(text.hashCode());
                default -> key = text; // "text"
            }
            uniq.putIfAbsent(key, c);
        }

        // 2) ê²½ëŸ‰ 1ì°¨ ë­í‚¹ (ì—†ìœ¼ë©´ candidates ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        List<Content> candidates = new ArrayList<>(uniq.values());
        List<Content> firstPass = (lightWeightRanker != null)
                ? lightWeightRanker.rank(
                candidates,
                Optional.ofNullable(queryText).orElse(""),
                Math.max(topK * 2, 20)
        )
                : candidates;

        //  ì›ì†Œ ì œì•½ ê¸°ë°˜ ë³´ì •(ì¶”ì²œ ì˜ë„Â·ì œì•½ì€ ì „ì²˜ë¦¬ê¸°ì—ì„œ ìœ ë„)
        if (elementConstraintScorer != null) {
            try {
                firstPass = elementConstraintScorer.rescore(
                        Optional.ofNullable(queryText).orElse(""),
                        firstPass
                );
            } catch (Exception ignore) { /* ì•ˆì „ ë¬´ì‹œ */ }
        }

        // 2-B) ğŸ”´ (ì˜µì…˜) êµì°¨ì—”ì½”ë” ì¬ì •ë ¬: ì§ˆë¬¸ê³¼ì˜ ì˜ë¯¸ ìœ ì‚¬ë„ ì •ë°€ ì¬ê³„ì‚°
        // - ê°œì„ : í›„ë³´ í¬ê¸°ë¿ë§Œ ì•„ë‹ˆë¼ êµ¬ì„± ê°€ëŠ¥í•œ ì¬ë­ì»¤ ê²Œì´íŠ¸ì— ìœ„ì„í•˜ì—¬ ì‹¤í–‰ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        if (crossEncoderReranker != null && !firstPass.isEmpty()) {
            boolean shouldRerank = true;
            try {
                if (rerankGate != null) {
                    shouldRerank = rerankGate.shouldRerank(firstPass);
                }
            } catch (Exception e) {
                // Fail-soft: if the gate fails, fall back to original size check
                shouldRerank = firstPass.size() >= rerankCeTopK;
                log.debug("[Hybrid] rerankGate error {}; falling back to size check", e.toString());
            }
            if (shouldRerank) {
                boolean allowed = true;
                // Acquire a short cooldown lock to prevent thundering herd rerank calls.  When
                // the lock cannot be obtained the expensive cross-encoder rerank is skipped.
                if (cooldownService != null) {
                    try {
                        String baseKey = Optional.ofNullable(queryText).orElse("");
                        String digest = org.apache.commons.codec.digest.DigestUtils.md5Hex(baseKey);
                        String key = "ce:rerank:" + digest;
                        allowed = cooldownService.setNxEx(key, "1", 1);
                        if (!allowed) {
                            log.debug("[Hybrid] cross-encoder rerank skipped due to cooldown lock");
                        }
                    } catch (Exception ignore) {
                        // fallback to allow rerank if lock acquisition fails
                        allowed = true;
                    }
                }
                if (allowed) {
                    try {
                        firstPass = crossEncoderReranker.rerank(
                                Optional.ofNullable(queryText).orElse(""),
                                firstPass,
                                Math.max(topK * 2, 20)
                        );
                    } catch (Exception e) {
                        log.debug("[Hybrid] cross-encoder rerank skipped due to error: {}", e.toString());
                    }
                }
            } else {
                log.debug("[Hybrid] cross-encoder rerank skipped by gate");
            }
        }

        // 3) ì •ë°€ ìŠ¤ì½”ì–´ë§ + ì •ë ¬
        class Scored {
            final Content content;
            final double score;
            Scored(Content content, double score) { this.content = content; this.score = score; }
        }
        List<Scored> scored = new ArrayList<>();
        int rank = 0;
        // â˜… NEW: ë™ì  ë­í‚¹ ê°€ì¤‘ì¹˜/ë³´ë„ˆìŠ¤
        final double wRel  = hp.getDouble("retrieval.rank.w.rel",  0.60);
        final double wBase = hp.getDouble("retrieval.rank.w.base", 0.30);
        final double wAuth = hp.getDouble("retrieval.rank.w.auth", 0.10);
        final double bonusOfficial = hp.getDouble("retrieval.rank.bonus.official", 0.20);

        // â˜… NEW: ML ë³´ì • ê³„ìˆ˜
        final double alpha  = hp.getDouble("ml.correction.alpha",  0.0);
        final double beta   = hp.getDouble("ml.correction.beta",   0.0);
        final double gamma  = hp.getDouble("ml.correction.gamma",  0.0);
        final double d0     = hp.getDouble("ml.correction.d0",     0.0);
        final double mu     = hp.getDouble("ml.correction.mu",     0.0);
        final double lambda = hp.getDouble("ml.correction.lambda", 1.0);

        for (Content c : firstPass) {
            rank++;
            double base = 1.0 / rank;

            String text = Optional.ofNullable(c.textSegment())
                    .map(TextSegment::text)
                    .orElse(c.toString());

            String url = extractUrl(text);

            double authority = authorityScorer != null ? authorityScorer.weightFor(url) : 0.5;

            double rel = 0.0;
            try {
                rel = relevanceScoringService.relatedness(
                        Optional.ofNullable(queryText).orElse(""),
                        text
                );
            } catch (Exception ignore) { }

            // â˜… NEW: ìµœì¢… ì ìˆ˜ = wRel*ê´€ë ¨ë„ + wBase*ê¸°ë³¸ë­í¬ + wAuth*Authority (+ê³µì‹ë„ë©”ì¸ ë³´ë„ˆìŠ¤)
            double score0 = (wRel * rel) + (wBase * base) + (wAuth * authority);
            if (isOfficial(url, officialDomains)) {
                score0 += bonusOfficial;
            }
            // â˜… NEW: ML ë¹„ì„ í˜• ë³´ì •(ì˜µì…˜) - ê°’åŸŸ ë³´ì • ë° tail ì œì–´
            double finalScore = useMlCorrection
                    ? MLCalibrationUtil.finalCorrection(score0, alpha, beta, gamma, d0, mu, lambda, true)
                    : score0;
            scored.add(new Scored(c, finalScore));
        }

        scored.sort((a, b) -> Double.compare(b.score, a.score));
        return scored.stream()
                .limit(topK)
                .map(s -> s.content)
                .collect(Collectors.toList());
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NEW: Softmax ìœµí•©(ë‹¨ì¼ ì •ì˜ë§Œ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    /** ì—¬ëŸ¬ ë²„í‚·ì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ëª¨ì•„ ì ìˆ˜(logit)ë¥¼ ë§Œë“¤ê³  softmaxë¡œ ì •ê·œí™”í•œ ë’¤ ìƒìœ„ Nì„ ê³ ë¥¸ë‹¤. */
    private List<Content> fuseWithSoftmax(List<List<Content>> buckets, int limit, String queryText) {
        Map<String, Content> keeper = new LinkedHashMap<>();
        Map<String, Double>  logit  = new LinkedHashMap<>();

        int bIdx = 0;
        for (List<Content> bucket : buckets) {
            if (bucket == null) continue;
            int rank = 0;
            for (Content c : bucket) {
                rank++;
                String text = Optional.ofNullable(c.textSegment()).map(TextSegment::text).orElse(c.toString());
                String key  = Integer.toHexString(text.hashCode()); // ê°„ë‹¨ dedupe
                String url  = extractUrl(text);
                double authority = (authorityScorer != null) ? authorityScorer.weightFor(url) : 0.5;
                double related   = 0.0;
                try { related = relevanceScoringService.relatedness(Optional.ofNullable(queryText).orElse(""), text); } catch (Exception ignore) {}
                double base      = 1.0 / (rank + 0.0);           // ìƒìœ„ ë­í¬ ê°€ì¤‘
                double bucketW   = 1.0 / (bIdx + 1.0);           // ì•ì„  ë²„í‚· ì•½ê°„ ìš°ëŒ€
                double l = (0.6 * related) + (0.1 * authority) + (0.3 * base * bucketW);

                keeper.putIfAbsent(key, c);
                logit.merge(key, l, Math::max); // ê°™ì€ ë¬¸ì„œëŠ” ê°€ì¥ ë†’ì€ logitë§Œ ìœ ì§€
            }
            bIdx++;
        }
        if (logit.isEmpty()) return List.of();

        // softmax ì •ê·œí™”(ìˆ˜ì¹˜ ì•ˆì •í™” í¬í•¨) í›„ í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        String[] keys = logit.keySet().toArray(new String[0]);
        // Extract logits as a primitive array.  These values will be calibrated
        // before applying softmax.  Calibration helps ensure the logits occupy
        // a comparable range across different queries, improving the softmax
        // distribution.  When calibration is disabled the original values are
        // passed through unchanged.
        double[] scores = logit.values().stream().mapToDouble(Double::doubleValue).toArray();
        try {
            if ("minmax".equalsIgnoreCase(softmaxCalibration)) {
                scores = com.example.lms.service.rag.fusion.FusionCalibrator.minMax(scores);
            } else if ("isotonic".equalsIgnoreCase(softmaxCalibration)) {
                // shim for isotonic regression.  Fall back to minmax
                // scaling until an isotonic calibrator is implemented.
                scores = com.example.lms.service.rag.fusion.FusionCalibrator.minMax(scores);
            }
        } catch (Exception e) {
            log.debug("[Hybrid] softmax calibration failed: {}", e.toString());
        }
        // Compute softmax probabilities with the calibrated scores.
        double[] p    = SoftmaxUtil.softmax(scores, fusionTemperature);

        // í™•ë¥  ë‚´ë¦¼ì°¨ìˆœ ìƒìœ„ limit
        java.util.List<Integer> idx = new java.util.ArrayList<>();
        for (int i = 0; i < p.length; i++) idx.add(i);
        idx.sort((i, j) -> Double.compare(p[j], p[i]));

        java.util.List<Content> out = new java.util.ArrayList<>();
        for (int i = 0; i < Math.min(limit, idx.size()); i++) {
            out.add(keeper.get(keys[idx.get(i)]));
        }
        return out;
    }


    // [HARDENING] ensure SID metadata is present on every query
    private dev.langchain4j.rag.query.Query ensureSidMetadata(dev.langchain4j.rag.query.Query original, String sessionKey) {
        // Always build a new query with the correct session metadata using QueryUtils. This
        // helper constructs the proper Metadata object and avoids deprecated builder APIs.
        // The chat history is omitted (null) in this context.
        return QueryUtils.buildQuery(original.text(), sessionKey, null);
    }

}