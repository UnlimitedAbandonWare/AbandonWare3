package com.example.lms.service.rag;

import com.example.lms.service.NaverSearchService;
import dev.langchain4j.rag.content.Content;
import dev.langchain4j.rag.content.retriever.ContentRetriever;
import dev.langchain4j.rag.query.Query;
import lombok.RequiredArgsConstructor;
import java.util.List;
import com.example.lms.service.rag.filter.GenericDocClassifier;
import com.example.lms.service.rag.detector.GameDomainDetector;
import com.example.lms.service.rag.filter.EducationDocClassifier;
import org.slf4j.LoggerFactory;
import org.slf4j.Logger;


import java.util.regex.Pattern;             /* ğŸ”´ NEW */
@RequiredArgsConstructor
@org.springframework.stereotype.Component
public class WebSearchRetriever implements ContentRetriever {
    private static final Logger log = LoggerFactory.getLogger(WebSearchRetriever.class);
    private final NaverSearchService searchSvc;
    /**
     * Aggregate web search across multiple providers.  This component fans
     * out to the configured {@link com.acme.aicore.domain.ports.WebSearchProvider}
     * implementations (Bing/Naver/Brave) in priority order and merges the
     * results.  When present it allows the web retrieval stage to fall
     * back to additional providers when the primary Naver results are
     * insufficient.  It is optional and may be null when no providers
     * are configured.
     */
    private final com.acme.aicore.adapters.search.CachedWebSearch multiSearch;
    // ìŠ¤í”„ë§ í”„ë¡œí¼í‹°ë¡œ ì£¼ì…(ìƒì„±ì ì£¼ì…ì˜ int ë¹ˆ ë¬¸ì œ íšŒí”¼)
    @org.springframework.beans.factory.annotation.Value("${rag.search.top-k:5}")
    private int topK;
    private final com.example.lms.service.rag.extract.PageContentScraper pageScraper;
    private static final int MIN_SNIPPETS = 2;
    //  ë„ë©”ì¸ ì‹ ë¢°ë„ ì ìˆ˜ë¡œ ì •ë ¬ ê°€ì¤‘
    private final com.example.lms.service.rag.auth.AuthorityScorer authorityScorer;
    // ë²”ìš© íŒì •ê¸°ëŠ” ì£¼ì…ë°›ì•„ ë„ë©”ì¸ë³„ë¡œ ë™ì‘í•˜ë„ë¡ í•œë‹¤.
    private final GenericDocClassifier genericClassifier;
    // ì§ˆì˜ ë„ë©”ì¸ ì¶”ì •ê¸°
    private final com.example.lms.service.rag.detector.GameDomainDetector domainDetector;
    // êµìœ¡ í† í”½ ë¶„ë¥˜ê¸°: êµìœ¡ ë„ë©”ì¸ì¼ ë•Œ ìŠ¤ë‹ˆí« í•„í„°ë§ì— ì‚¬ìš©ëœë‹¤.
    private final com.example.lms.service.rag.filter.EducationDocClassifier educationClassifier;
    private static final Pattern META_TAG = Pattern.compile("\\[[^\\]]+\\]");
    private static final Pattern TIME_TAG = Pattern.compile("\\b\\d{1,2}:\\d{2}\\b");
    /* ğŸ”µ ë´‡/ìº¡ì°¨ í˜ì´ì§€ íŒíŠ¸ */
    /* DuckDuckGo ë“±ì—ì„œ ë°˜í™˜ë˜ëŠ” ìº¡ì°¨/ë´‡ ì°¨ë‹¨ íŒíŠ¸ ì œê±°ìš© */
    private static final Pattern CAPTCHA_HINT = Pattern.compile(
            "(?i)(captcha|are you (a )?robot|unusual\\s*traffic|verify you are human|duckduckgo\\.com/captcha|bots\\s*use\\s*duckduckgo)");


    private static String normalize(String raw) {        /* ğŸ”´ NEW */
        if (raw == null) return "";

        String s = META_TAG.matcher(raw).replaceAll("");
        s = TIME_TAG.matcher(s).replaceAll("");
        return s.replace("\n", " ").trim();
    }

    /**
     * Extract a version token from the query string.  A version is defined
     * as two numeric components separated by a dot or middot character.  If
     * no such token is present, {@code null} is returned.
     *
     * @param q the query text
     * @return the extracted version (e.g. "5.8") or null
     */
    private static String extractVersion(String q) {
        if (q == null) return null;
        java.util.regex.Matcher m = java.util.regex.Pattern.compile("(\\d+)[\\.Â·](\\d+)").matcher(q);
        return m.find() ? (m.group(1) + "." + m.group(2)) : null;
    }

    /**
     * Build a regex that matches the exact version token in text.  Dots in
     * the version are replaced with a character class that matches dot or
     * middot to handle variations in punctuation.  Anchors ensure that
     * longer numbers containing the version as a substring are not falsely
     * matched.
     *
     * @param v the version string (e.g. "5.8")
     * @return a compiled regex pattern matching the exact token
     */
    private static java.util.regex.Pattern versionRegex(String v) {
        String core = v.replace(".", "[\\.Â·\\s]");
        return java.util.regex.Pattern.compile("(?<!\\d)" + core + "(?!\\d)");
    }

    /* âœ… ì„ í˜¸ ë„ë©”ì¸: ì œê±°ê°€ ì•„ë‹Œ 'ìš°ì„  ì •ë ¬'ë§Œ ìˆ˜í–‰ */
    private static final List<String> PREFERRED = List.of(
            // ê³µì‹/ê¶Œìœ„
            "genshin.hoyoverse.com", "hoyoverse.com", "hoyolab.com",
            "wikipedia.org", "eulji.ac.kr", "ac.kr", "go.kr",
            // í•œêµ­ ì»¤ë®¤ë‹ˆí‹°Â·ë¸”ë¡œê·¸(ì‚­ì œ X, ë‹¨ì§€ í›„ìˆœìœ„)
            "namu.wiki", "blog.naver.com"
    );
    private static boolean containsPreferred(String s) {
        return PREFERRED.stream().anyMatch(s::contains);
    }

    @Override
    public List<Content> retrieve(Query query) {
        String normalized = normalize(query != null ? query.text() : "");
        // ì¿¼ë¦¬ ë„ë©”ì¸ ì¶”ì •: null ê°€ëŠ¥ì„±ì„ ê³ ë ¤í•˜ì—¬ GENERAL ê¸°ë³¸ê°’ ì‚¬ìš©
        String domain = domainDetector != null ? domainDetector.detect(normalized) : "GENERAL";
        boolean isGeneral = "GENERAL".equalsIgnoreCase(domain);

        // Extract a version token from the query.  When present, enforce that
        // each snippet contains the exact version.  This helps prevent
        // contamination from neighbouring versions (e.g. 5.7 or 5.9) when the
        // user asks about a specific patch.
        String ver = extractVersion(normalized);
        java.util.regex.Pattern must = (ver != null) ? versionRegex(ver) : null;
        // 1) 1ì°¨ ìˆ˜ì§‘: topK*2 â†’ ì¤‘ë³µ/ì •ë ¬ í›„ topK
        List<String> first = searchSvc.searchSnippets(normalized, Math.max(topK, 1) * 2)
                .stream()
                .filter(s -> !CAPTCHA_HINT.matcher(s).find())  // ğŸ”’ ìº¡ì°¨ ë…¸ì´ì¦ˆ ì»·
                .filter(s -> must == null || must.matcher(s).find()) // enforce version token when necessary
                // cut tag pages early (/tag/ or ?tag=)
                .filter(s -> {
                    String url = extractUrl(s);
                    if (url == null) return true;
                    String lower = url.toLowerCase();
                    return !(lower.contains("/tag/") || lower.contains("?tag="));
                })
                .toList();

        // ğŸš€ Fan-out to additional providers via CachedWebSearch.  When the
        // primary Naver results are fewer than the desired count, fetch
        // supplementary snippets from other providers (e.g. Bing/Brave).  The
        // CachedWebSearch component merges provider responses according to
        // provider priorities and caches the result.  Failures are
        // intentionally swallowed to avoid impacting the main retrieval.
        List<String> supplemental = java.util.Collections.emptyList();
        if (multiSearch != null) {
            try {
                var q = new com.acme.aicore.domain.model.WebSearchQuery(normalized);
                // Limit fanout to three providers (Bing, Naver, Brave) and
                // block for up to 3 seconds to avoid blocking the caller.
                var bundle = multiSearch.searchMulti(q, 3)
                        .block(java.time.Duration.ofSeconds(3));
                if (bundle != null && bundle.docs() != null) {
                    supplemental = bundle.docs().stream()
                            .map(d -> {
                                String core = (d.title() + " - " + d.snippet()).trim();
                                return core.isBlank() ? d.url() : core;
                            })
                            .filter(s -> s != null && !s.isBlank())
                            .toList();
                }
            } catch (Exception e) {
                // ignore errors; supplemental remains empty
            }
        }

        // Prepend the supplemental results to the primary list, ensuring
        // duplicates are removed while preserving order.  This prioritises
        // provider results before applying ranking heuristics below.  Only
        // the first (topK*2) snippets are considered to limit memory usage.
        if (supplemental != null && !supplemental.isEmpty()) {
            java.util.LinkedHashSet<String> combined = new java.util.LinkedHashSet<>();
            combined.addAll(supplemental);
            combined.addAll(first);
            first = combined.stream().limit(Math.max(topK, 1) * 2).toList();
        }
        if (log.isDebugEnabled()) {
            log.debug("[WebSearchRetriever] first raw={} (q='{}')", first.size(), normalized);
        }
        // ì„ í˜¸+ ë„ë©”ì¸  Authority ê°€ì¤‘ ì •ë ¬(ì‚­ì œ ì•„ë‹˜). ë²”ìš© í˜ë„í‹°ëŠ” GENERAL/EDUCATION ë„ë©”ì¸ì—ì„œëŠ” ì œê±°
        List<String> ranked = first.stream()
                .distinct()
                .sorted((a, b) -> {
                    double aw = authorityScorer.weightFor(extractUrl(a))
                               - (isGeneral ? 0.0 : genericClassifier.penalty(a, domain));
                    double bw = authorityScorer.weightFor(extractUrl(b))
                               - (isGeneral ? 0.0 : genericClassifier.penalty(b, domain));
                    int cmp = Double.compare(bw, aw); // high first (penalty ë°˜ì˜)
                    if (cmp != 0) return cmp;
                    // ë™ë¥ ì´ë©´ ì„ í˜¸ ë„ë©”ì¸ ìš°ì„ 
                    return Boolean.compare(containsPreferred(b), containsPreferred(a));
                })
                .limit(topK)
                .toList();
        // ë²”ìš© ìŠ¤ë‹ˆí« ì»·: ë„ë©”ì¸ íŠ¹í™”(ì˜ˆ: GENSHIN/EDU)ì—ì„œë§Œ ì ìš©
        if (!isGeneral) {
            ranked = ranked.stream()
                    .filter(s -> !genericClassifier.isGenericSnippet(s, domain))
                    .limit(topK)
                    .toList();
        }

        // 2) í´ë°±: ì§€ë‚˜ì¹œ ê³µì†ì–´/í˜¸ì¹­ ì •ë¦¬
        List<String> fallback = ranked.size() >= MIN_SNIPPETS ? List.of()
                : searchSvc.searchSnippets(normalized.replace("êµìˆ˜ë‹˜", "êµìˆ˜").replace("ë‹˜",""), topK);

        List<String> finalSnippets = java.util.stream.Stream.of(ranked, fallback)
                .flatMap(java.util.Collection::stream)
                .distinct()
                .limit(topK)
                .toList();

        // If the detected domain is EDUCATION, apply an education topic filter
        // to remove snippets that are unrelated to education/academy topics.  This
        // leverages the EducationDocClassifier to detect whether a snippet is
        // genuinely about education.  Without this filter generic or noise
        // snippets from pet or automotive sites may contaminate the retrieval.
        if ("EDUCATION".equalsIgnoreCase(domain) && educationClassifier != null) {
            finalSnippets = finalSnippets.stream()
                    .filter(s -> {
                        try {
                            return educationClassifier.isEducation(s);
                        } catch (Exception e) {
                            return true;
                        }
                    })
                    .limit(topK)
                    .toList();
        }

        if (log.isDebugEnabled()) {
            log.debug("[WebSearchRetriever] selected={} (topK={})", finalSnippets.size(), topK);
        }
        // 3) ê° ê²°ê³¼ì˜ URL ë³¸ë¬¸ì„ ì½ì–´ â€˜ì§ˆë¬¸-ìœ ì‚¬ë„â€™ë¡œ í•µì‹¬ ë¬¸ë‹¨ ì¶”ì¶œ
        java.util.List<Content> out = new java.util.ArrayList<>();
        for (String s : finalSnippets) {
            String url = extractUrl(s);   // â¬…ï¸ ì—†ë˜ util ë©”ì„œë“œ ì¶”ê°€(ì•„ë˜)
            if (url == null || CAPTCHA_HINT.matcher(s).find()) { // ğŸ”’ ì˜ì‹¬ ë¼ì¸ ìŠ¤í‚µ
                out.add(Content.from(s)); // URL ì—†ìŒ â†’ ê¸°ì¡´ ìŠ¤ë‹ˆí« ì‚¬ìš©
                continue;
            }
            try {
                String body = pageScraper.fetchText(url, /*timeoutMs*/6000);
                // SnippetPrunerëŠ” (String, String) ì‹œê·¸ë‹ˆì²˜ë§Œ ì¡´ì¬ â†’ ë‹¨ì¼ ê²°ê³¼ë¡œ ì²˜ë¦¬
                // ğŸ”µ ìš°ë¦¬ ìª½ ê°„ë‹¨ ë”¥ ìŠ¤ë‹ˆí« ì¶”ì¶œ(ì„ë² ë”© ì—†ì´ í‚¤ì›Œë“œ/ê¸¸ì´ ê¸°ë°˜)
                String picked = pickByHeuristic(query.text(), body, 480);
                if (picked == null || picked.isBlank()) {
                    out.add(Content.from(s));
                } else {
                    out.add(Content.from(picked + "\n\n[ì¶œì²˜] " + url));
                }
            } catch (Exception e) {
                log.debug("[WebSearchRetriever] scrape fail {} â†’ fallback snippet", url);
                out.add(Content.from(s));
            }
        }
        return out.stream().limit(topK).toList();
    }

    // â”€â”€ NEW: ìŠ¤ë‹ˆí« ë¬¸ìì—´ì—ì„œ URLì„ ë½‘ì•„ë‚´ëŠ” ê°„ë‹¨ íŒŒì„œ(í”„ë¡œì íŠ¸ ì „ë°˜ ë™ì¼ ê·œì¹™ê³¼ ì¼ì¹˜)
    private static String extractUrl(String text) {
        if (text == null) return null;
        int a = text.indexOf("href=\"");
        if (a >= 0) {
            int s = a + 6, e = text.indexOf('"', s);
            if (e > s) return text.substring(s, e);
        }
        int http = text.indexOf("http");
        if (http >= 0) {
            int sp = text.indexOf(' ', http);
            return sp > http ? text.substring(http, sp) : text.substring(http);
        }
        return null;
    }
    // â”€â”€ NEW: SnippetPruner ì—†ì´ë„ ë™ì‘í•˜ëŠ” ê²½ëŸ‰ ë”¥ ìŠ¤ë‹ˆí« ì¶”ì¶œê¸°
    private static String pickByHeuristic(String q, String body, int maxLen) {
        if (body == null || body.isBlank()) return "";
        if (q == null) q = "";
        String[] toks = q.toLowerCase().split("\\s+");
        String[] sents = body.split("(?<=[\\.\\?\\!ã€‚ï¼ï¼Ÿ])\\s+");
        String best = "";
        int bestScore = -1;
        for (String s : sents) {
            if (s == null || s.isBlank()) continue;
            String ls = s.toLowerCase();
            int score = 0;
            for (String t : toks) {
                if (t.isBlank()) continue;
                if (ls.contains(t)) score += 2;      // ì§ˆì˜ í† í° í¬í•¨ ê°€ì¤‘
            }
            score += Math.min(s.length(), 300) / 60;   // ë¬¸ì¥ ê¸¸ì´ ê°€ì¤‘(ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ íŒ¨ë„í‹°)
            if (score > bestScore) { bestScore = score; best = s.trim(); }
        }
        if (best.isEmpty()) {
            best = body.length() > maxLen ? body.substring(0, maxLen) : body;
        } else if (best.length() > maxLen) {
            best = best.substring(0, maxLen) + "/* ... *&#47;";
        }
        return best;
    }
}